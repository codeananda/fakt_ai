{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-01T08:55:24.677489Z",
     "start_time": "2024-08-01T08:55:18.803758Z"
    }
   },
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import SerperDevTool\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(raise_error_if_not_found=True))\n",
    "\n",
    "os.environ['OPENAI_MODEL_NAME'] = \"gpt-4o-mini\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T08:55:24.690367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_tool = SerperDevTool()\n",
    "\n",
    "# Define your agents with roles and goals\n",
    "pro_researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Find many (10+) arguments, papers, websites, and blog posts that support a given statement.',\n",
    "  backstory=\"\"\"You work at a leading research institution and are known for your thoroughness and ability\n",
    "  to search deep into the web to find the most relevant information supporting statements.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  # You can pass an optional llm attribute specifying what model you wanna use.\n",
    "  # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7),\n",
    "  tools=[search_tool]\n",
    ")\n",
    "con_researcher = Agent(\n",
    "    role='Senior Research Analyst',\n",
    "    goal='Find many (10+) arguments, papers, websites, and blog posts that argue against a given statement.',\n",
    "    backstory=\"\"\"You work at a leading research institution and are known for your thoroughness and ability\n",
    "    to search deep into the web to find the most relevant information that disagrees with particular statements.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    # You can pass an optional llm attribute specifying what model you wanna use.\n",
    "    # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7),\n",
    "    tools=[search_tool]\n",
    ")\n",
    "writer = Agent(\n",
    "  role='Summariser',\n",
    "  goal='Summarize the arguments found by the pro and con researchers into a coherent and concise report',\n",
    "  backstory=\"\"\"You are a skilled writer and summarizer, known for your ability to distill complex information\n",
    "  into clear and concise summaries. You clearly present both sides of an argument.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True\n",
    ")\n",
    "\n",
    "# Create tasks for your agents\n",
    "pro_arguments_task = Task(\n",
    "  description=\"\"\"Find 10+ resources from a wide range of sources that support the following statement: {statement}\"\"\",\n",
    "  expected_output=\"Links to 10+ resources supporting the statement, including a title for each and a short summary of\"\n",
    "                  \"the position taken in each resource.\",\n",
    "  agent=pro_researcher,\n",
    ")\n",
    "\n",
    "con_arguments_task = Task(\n",
    "  description=\"\"\"Find 10+ resources from a wide range of sources that argue against the following statement: {statement}\"\"\",\n",
    "  expected_output=\"Links to 10+ resources arguing against the statement, including a title for each and a short summary of\"\n",
    "                  \"the position taken in each resource.\",\n",
    "  agent=con_researcher,\n",
    ")\n",
    "\n",
    "summarise_arguments_task = Task(\n",
    "  description=\"\"\"Using the inputs provided by the pro and con researchers, summarize the arguments found into a coherent\n",
    "  and concise report. Include a brief overview of the main points made by each side, highlighting the key arguments and\n",
    "  counterarguments.\"\"\",\n",
    "  expected_output=\"Full blog post of at least 4 paragraphs\",\n",
    "  agent=writer\n",
    ")\n",
    "\n",
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[pro_researcher,con_researcher, writer],\n",
    "  tasks=[pro_arguments_task, con_arguments_task, summarise_arguments_task],\n",
    "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
    "  process = Process.sequential\n",
    ")\n",
    "\n",
    "statement = \"\"\"While the CDC team found that 1 in 1,000,000 patients was injured by vaccines, the Lazarus team found that 1 in 37 kids had potential claims for vaccine injuries\"\"\"\n",
    "result = crew.kickoff({\"statement\": statement})\n",
    "\n",
    "print(\"######################\")\n",
    "print(result)"
   ],
   "id": "40c30cb8080a4642",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[95m [2024-08-01 10:55:24][DEBUG]: == Working Agent: Senior Research Analyst\u001B[00m\n",
      "\u001B[1m\u001B[95m [2024-08-01 10:55:24][INFO]: == Starting Task: Find 10+ resources from a wide range of sources that support the following statement: While the CDC team found that 1 in 1,000,000 patients was injured by vaccines, the Lazarus team found that 1 in 37 kids had potential claims for vaccine injuries\u001B[00m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new CrewAgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mAction: Search the internet  \n",
      "Action Input: {\"search_query\": \"CDC vaccine injury statistics 1 in 1,000,000 Lazarus team 1 in 37 kids claims\"}  \u001B[0m\u001B[95m \n",
      "\n",
      "\n",
      "Search results: Title: Fact check: A 2010 study on vaccines did not show that one in forty ...\n",
      "Link: https://www.reuters.com/article/world/fact-check-a-2010-study-on-vaccines-did-not-show-that-one-in-forty-were-damaged-idUSKBN28Q2V6/\n",
      "Snippet: A video posted on Facebook by an anti-lockdown activist, citing a 2010 vaccination study, claims that one in forty have “vaccine damage.\n",
      "---\n",
      "Title: Vaccine Adverse Event Reporting System (VAERS) Publications\n",
      "Link: https://www.cdc.gov/vaccinesafety/ensuringsafety/monitoring/vaers/publications.html\n",
      "Snippet: The overall VAERS reporting rate was 1,596 reports per million doses administered. V-safe had 213 participants register and complete at least one health survey ...\n",
      "---\n",
      "Title: Multiple Vaccinations and the Enigma of Vaccine Injury - PMC - NCBI\n",
      "Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7712358/\n",
      "Snippet: In a study based on 38,801 reports to VAERS, a linear relationship was observed between the number of vaccine doses administered at one time and ...\n",
      "---\n",
      "Title: VAERS | Vaccine Safety - CDC\n",
      "Link: https://www.cdc.gov/vaccinesafety/ensuringsafety/monitoring/vaers/index.html\n",
      "Snippet: Learn more about the difference between side effects and adverse events after vaccination. The latest vaccine safety research and safety studies from CDC.\n",
      "---\n",
      "Title: Selected Adverse Events Reported after COVID-19 Vaccination - CDC\n",
      "Link: https://www.cdc.gov/coronavirus/2019-ncov/vaccines/safety/adverse-events.html\n",
      "Snippet: Anaphylaxis after COVID-19 vaccination is rare. It has occurred at a rate of approximately 5 cases per one million vaccine doses administered.\n",
      "---\n",
      "Title: Chapter 21: Surveillance for Adverse Events Following ... - CDC\n",
      "Link: https://www.cdc.gov/vaccines/pubs/surv-manual/chpt21-surv-adverse-events.html\n",
      "Snippet: [1] Vaccines have reduced the incidence of many vaccine-preventable diseases in the United States by more than 98% compared to the pre-vaccine ...\n",
      "---\n",
      "Title: [PDF] r18hs017045-lazarus-final-report-2011.pdf\n",
      "Link: https://digital.ahrq.gov/sites/default/files/docs/publication/r18hs017045-lazarus-final-report-2011.pdf\n",
      "Snippet: Comprehensively evaluate ESP:VAERS performance in a randomized trial, and in comparison to existing VAERS and Vaccine Safety Datalink data. Aim ...\n",
      "---\n",
      "Title: ACIP Adverse Reactions Guidelines for Immunization - CDC\n",
      "Link: https://www.cdc.gov/vaccines/hcp/acip-recs/general-recs/adverse-reactions.html\n",
      "Snippet: The National Childhood Vaccine Injury Act of 1986 (1) requires that vaccine ... rate of approximately one per million doses for many vaccines (5).\n",
      "---\n",
      "Title: FactChecking Robert F. Kennedy Jr.\n",
      "Link: https://www.factcheck.org/2023/08/scicheck-factchecking-robert-f-kennedy-jr/\n",
      "Snippet: As supposed evidence of vaccine harm, Kennedy frequently refers to what he calls the “Lazarus study.” “Fewer than 1 in 100 vaccine injuries ...\n",
      "---\n",
      "Title: Historical Vaccine Safety Concerns - CDC\n",
      "Link: https://www.cdc.gov/vaccinesafety/concerns/concerns-history.html\n",
      "Snippet: Read more about past vaccine safety concerns, how they have been resolved, and what we have learned.\n",
      "---\n",
      "\n",
      "\u001B[00m\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
